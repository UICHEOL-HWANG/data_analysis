{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeeecc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import koreanize_matplotlib\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30839a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/wine.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9a8e954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
       "\n",
       "      11  12  \n",
       "0      5   1  \n",
       "1      5   1  \n",
       "2      5   1  \n",
       "3      6   1  \n",
       "4      5   1  \n",
       "...   ..  ..  \n",
       "6492   6   0  \n",
       "6493   5   0  \n",
       "6494   6   0  \n",
       "6495   7   0  \n",
       "6496   6   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d349b123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6497 entries, 0 to 6496\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       6497 non-null   float64\n",
      " 1   1       6497 non-null   float64\n",
      " 2   2       6497 non-null   float64\n",
      " 3   3       6497 non-null   float64\n",
      " 4   4       6497 non-null   float64\n",
      " 5   5       6497 non-null   float64\n",
      " 6   6       6497 non-null   float64\n",
      " 7   7       6497 non-null   float64\n",
      " 8   8       6497 non-null   float64\n",
      " 9   9       6497 non-null   float64\n",
      " 10  10      6497 non-null   float64\n",
      " 11  11      6497 non-null   int64  \n",
      " 12  12      6497 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 660.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b37387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(12,axis=1)\n",
    "y = data[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6a8adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4,random_state=1)\n",
    "X_valid,X_test,y_valid,y_test = train_test_split(X_test,y_test,test_size=0.5,random_state=1) # cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38fe668e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3898, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf4e143d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1299, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaf2a02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1300, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0902e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b9d96bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                390       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                372       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30,input_dim=X_train.shape[1],activation=\"relu\"))\n",
    "model.add(Dense(12,activation=\"relu\"))\n",
    "model.add(Dense(8,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b561f0aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 43ms/step - loss: 1.5164 - accuracy: 0.7482 - val_loss: 1.1089 - val_accuracy: 0.7610\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8710 - accuracy: 0.7485 - val_loss: 0.4683 - val_accuracy: 0.7672\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4433 - accuracy: 0.7940 - val_loss: 0.4908 - val_accuracy: 0.8544\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3731 - accuracy: 0.8690 - val_loss: 0.3151 - val_accuracy: 0.8718\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3295 - accuracy: 0.8580 - val_loss: 0.3111 - val_accuracy: 0.8831\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2866 - accuracy: 0.8731 - val_loss: 0.2446 - val_accuracy: 0.9046\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2395 - accuracy: 0.9138 - val_loss: 0.2401 - val_accuracy: 0.9231\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2261 - accuracy: 0.9319 - val_loss: 0.2177 - val_accuracy: 0.9272\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2088 - accuracy: 0.9312 - val_loss: 0.2168 - val_accuracy: 0.9272\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2050 - accuracy: 0.9357 - val_loss: 0.2123 - val_accuracy: 0.9344\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1998 - accuracy: 0.9391 - val_loss: 0.2111 - val_accuracy: 0.9354\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1982 - accuracy: 0.9412 - val_loss: 0.2089 - val_accuracy: 0.9354\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1951 - accuracy: 0.9381 - val_loss: 0.2078 - val_accuracy: 0.9364\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1926 - accuracy: 0.9381 - val_loss: 0.2057 - val_accuracy: 0.9344\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1905 - accuracy: 0.9391 - val_loss: 0.2039 - val_accuracy: 0.9344\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1887 - accuracy: 0.9384 - val_loss: 0.2018 - val_accuracy: 0.9364\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1874 - accuracy: 0.9377 - val_loss: 0.2001 - val_accuracy: 0.9374\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1860 - accuracy: 0.9377 - val_loss: 0.1989 - val_accuracy: 0.9364\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1848 - accuracy: 0.9384 - val_loss: 0.1979 - val_accuracy: 0.9374\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1835 - accuracy: 0.9377 - val_loss: 0.1967 - val_accuracy: 0.9374\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1825 - accuracy: 0.9384 - val_loss: 0.1957 - val_accuracy: 0.9364\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1815 - accuracy: 0.9384 - val_loss: 0.1947 - val_accuracy: 0.9385\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1812 - accuracy: 0.9384 - val_loss: 0.1939 - val_accuracy: 0.9364\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1796 - accuracy: 0.9388 - val_loss: 0.1927 - val_accuracy: 0.9374\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1791 - accuracy: 0.9391 - val_loss: 0.1920 - val_accuracy: 0.9374\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1780 - accuracy: 0.9384 - val_loss: 0.1904 - val_accuracy: 0.9374\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1771 - accuracy: 0.9401 - val_loss: 0.1891 - val_accuracy: 0.9364\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1763 - accuracy: 0.9391 - val_loss: 0.1886 - val_accuracy: 0.9374\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1754 - accuracy: 0.9388 - val_loss: 0.1877 - val_accuracy: 0.9385\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1755 - accuracy: 0.9408 - val_loss: 0.1863 - val_accuracy: 0.9374\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1738 - accuracy: 0.9388 - val_loss: 0.1853 - val_accuracy: 0.9395\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1731 - accuracy: 0.9374 - val_loss: 0.1839 - val_accuracy: 0.9374\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1729 - accuracy: 0.9394 - val_loss: 0.1833 - val_accuracy: 0.9374\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1711 - accuracy: 0.9398 - val_loss: 0.1835 - val_accuracy: 0.9374\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1707 - accuracy: 0.9405 - val_loss: 0.1818 - val_accuracy: 0.9385\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1706 - accuracy: 0.9398 - val_loss: 0.1804 - val_accuracy: 0.9385\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1691 - accuracy: 0.9398 - val_loss: 0.1801 - val_accuracy: 0.9374\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1688 - accuracy: 0.9405 - val_loss: 0.1786 - val_accuracy: 0.9395\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1674 - accuracy: 0.9408 - val_loss: 0.1779 - val_accuracy: 0.9395\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1676 - accuracy: 0.9401 - val_loss: 0.1769 - val_accuracy: 0.9395\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1660 - accuracy: 0.9405 - val_loss: 0.1762 - val_accuracy: 0.9395\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1656 - accuracy: 0.9408 - val_loss: 0.1752 - val_accuracy: 0.9395\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1650 - accuracy: 0.9405 - val_loss: 0.1742 - val_accuracy: 0.9405\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1638 - accuracy: 0.9401 - val_loss: 0.1734 - val_accuracy: 0.9395\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1633 - accuracy: 0.9422 - val_loss: 0.1727 - val_accuracy: 0.9395\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1626 - accuracy: 0.9415 - val_loss: 0.1720 - val_accuracy: 0.9415\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1624 - accuracy: 0.9425 - val_loss: 0.1707 - val_accuracy: 0.9395\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1611 - accuracy: 0.9415 - val_loss: 0.1706 - val_accuracy: 0.9415\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1600 - accuracy: 0.9432 - val_loss: 0.1692 - val_accuracy: 0.9395\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1598 - accuracy: 0.9442 - val_loss: 0.1682 - val_accuracy: 0.9415\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.9323\n",
      "loss : 0.17488890886306763\n",
      "accuracy : 0.9323077201843262\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer = \"adam\",metrics=['accuracy'])\n",
    "history = model.fit(X_train,y_train,epochs=50,batch_size=500,validation_split=0.25) # validation_split을 써서 vali data가 필요 없이 나눠준다? \n",
    "score = model.evaluate(X_test,y_test) \n",
    "print(f\"loss : {score[0]}\")\n",
    "print(f\"accuracy : {score[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a736057",
   "metadata": {},
   "source": [
    "## 학습 중 loss가 거의 변하지 않을 때 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0c6b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a84c6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./deep_model/{epoch:02d}-{val_accuracy:.4f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26911924",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./deep_model\\01-0.9405.hdf5\n",
      "\n",
      "Epoch 2: saving model to ./deep_model\\02-0.9405.hdf5\n",
      "\n",
      "Epoch 3: saving model to ./deep_model\\03-0.9415.hdf5\n",
      "\n",
      "Epoch 4: saving model to ./deep_model\\04-0.9415.hdf5\n",
      "\n",
      "Epoch 5: saving model to ./deep_model\\05-0.9426.hdf5\n",
      "\n",
      "Epoch 6: saving model to ./deep_model\\06-0.9415.hdf5\n",
      "\n",
      "Epoch 7: saving model to ./deep_model\\07-0.9426.hdf5\n",
      "\n",
      "Epoch 8: saving model to ./deep_model\\08-0.9436.hdf5\n",
      "\n",
      "Epoch 9: saving model to ./deep_model\\09-0.9436.hdf5\n",
      "\n",
      "Epoch 10: saving model to ./deep_model\\10-0.9436.hdf5\n",
      "\n",
      "Epoch 11: saving model to ./deep_model\\11-0.9446.hdf5\n",
      "\n",
      "Epoch 12: saving model to ./deep_model\\12-0.9446.hdf5\n",
      "\n",
      "Epoch 13: saving model to ./deep_model\\13-0.9426.hdf5\n",
      "\n",
      "Epoch 14: saving model to ./deep_model\\14-0.9446.hdf5\n",
      "\n",
      "Epoch 15: saving model to ./deep_model\\15-0.9446.hdf5\n",
      "\n",
      "Epoch 16: saving model to ./deep_model\\16-0.9456.hdf5\n",
      "\n",
      "Epoch 17: saving model to ./deep_model\\17-0.9446.hdf5\n",
      "\n",
      "Epoch 18: saving model to ./deep_model\\18-0.9456.hdf5\n",
      "\n",
      "Epoch 19: saving model to ./deep_model\\19-0.9446.hdf5\n",
      "\n",
      "Epoch 20: saving model to ./deep_model\\20-0.9456.hdf5\n",
      "\n",
      "Epoch 21: saving model to ./deep_model\\21-0.9456.hdf5\n",
      "\n",
      "Epoch 22: saving model to ./deep_model\\22-0.9456.hdf5\n",
      "\n",
      "Epoch 23: saving model to ./deep_model\\23-0.9456.hdf5\n",
      "\n",
      "Epoch 24: saving model to ./deep_model\\24-0.9467.hdf5\n",
      "\n",
      "Epoch 25: saving model to ./deep_model\\25-0.9467.hdf5\n",
      "\n",
      "Epoch 26: saving model to ./deep_model\\26-0.9477.hdf5\n",
      "\n",
      "Epoch 27: saving model to ./deep_model\\27-0.9456.hdf5\n",
      "\n",
      "Epoch 28: saving model to ./deep_model\\28-0.9487.hdf5\n",
      "\n",
      "Epoch 29: saving model to ./deep_model\\29-0.9477.hdf5\n",
      "\n",
      "Epoch 30: saving model to ./deep_model\\30-0.9487.hdf5\n",
      "\n",
      "Epoch 31: saving model to ./deep_model\\31-0.9487.hdf5\n",
      "\n",
      "Epoch 32: saving model to ./deep_model\\32-0.9477.hdf5\n",
      "\n",
      "Epoch 33: saving model to ./deep_model\\33-0.9477.hdf5\n",
      "\n",
      "Epoch 34: saving model to ./deep_model\\34-0.9477.hdf5\n",
      "\n",
      "Epoch 35: saving model to ./deep_model\\35-0.9487.hdf5\n",
      "\n",
      "Epoch 36: saving model to ./deep_model\\36-0.9477.hdf5\n",
      "\n",
      "Epoch 37: saving model to ./deep_model\\37-0.9508.hdf5\n",
      "\n",
      "Epoch 38: saving model to ./deep_model\\38-0.9497.hdf5\n",
      "\n",
      "Epoch 39: saving model to ./deep_model\\39-0.9497.hdf5\n",
      "\n",
      "Epoch 40: saving model to ./deep_model\\40-0.9528.hdf5\n",
      "\n",
      "Epoch 41: saving model to ./deep_model\\41-0.9528.hdf5\n",
      "\n",
      "Epoch 42: saving model to ./deep_model\\42-0.9559.hdf5\n",
      "\n",
      "Epoch 43: saving model to ./deep_model\\43-0.9508.hdf5\n",
      "\n",
      "Epoch 44: saving model to ./deep_model\\44-0.9569.hdf5\n",
      "\n",
      "Epoch 45: saving model to ./deep_model\\45-0.9610.hdf5\n",
      "\n",
      "Epoch 46: saving model to ./deep_model\\46-0.9559.hdf5\n",
      "\n",
      "Epoch 47: saving model to ./deep_model\\47-0.9662.hdf5\n",
      "\n",
      "Epoch 48: saving model to ./deep_model\\48-0.9610.hdf5\n",
      "\n",
      "Epoch 49: saving model to ./deep_model\\49-0.9641.hdf5\n",
      "\n",
      "Epoch 50: saving model to ./deep_model\\50-0.9559.hdf5\n",
      "41/41 [==============================] - 0s 781us/step - loss: 0.1130 - accuracy: 0.9562\n",
      "loss : 0.11304374039173126\n",
      "accuracy : 0.9561538696289062\n"
     ]
    }
   ],
   "source": [
    "check_pointer = ModelCheckpoint(filepath=model_path,verbose=1)\n",
    "history = model.fit(X_train,y_train,epochs=50,batch_size=500,validation_split=0.25,verbose=0,callbacks=[check_pointer]) # validation_split을 써서 vali data가 필요 없이 나눠준다? \n",
    "score = model.evaluate(X_test,y_test) \n",
    "print(f\"loss : {score[0]}\")\n",
    "print(f\"accuracy : {score[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd21e3a",
   "metadata": {},
   "source": [
    "## 학습 자동중단 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26b266a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "470c4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\",patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c054b789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9869\n",
      "loss : 0.057675670832395554\n",
      "accuracy : 0.986923098564148\n"
     ]
    }
   ],
   "source": [
    "check_pointer = ModelCheckpoint(filepath=model_path,monitor=\"val_loss\",verbose=0,save_best_only=True)\n",
    "history = model.fit(X_train,y_train,epochs=2000,batch_size=500,validation_split=0.25,verbose=0,callbacks=[early_stopping_callback,check_pointer]) # validation_split을 써서 vali data가 필요 없이 나눠준다? \n",
    "score = model.evaluate(X_test,y_test) \n",
    "print(f\"loss : {score[0]}\")\n",
    "print(f\"accuracy : {score[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf458978",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "880cf61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2741cad3d90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20b9a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(history.history,columns=history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e65da53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.054798</td>\n",
       "      <td>0.983579</td>\n",
       "      <td>0.056008</td>\n",
       "      <td>0.983590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.048680</td>\n",
       "      <td>0.984605</td>\n",
       "      <td>0.061054</td>\n",
       "      <td>0.980513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.043788</td>\n",
       "      <td>0.986315</td>\n",
       "      <td>0.057210</td>\n",
       "      <td>0.982564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.045296</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.052046</td>\n",
       "      <td>0.983590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.043013</td>\n",
       "      <td>0.985973</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.983590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.043163</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.054275</td>\n",
       "      <td>0.982564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.044497</td>\n",
       "      <td>0.986658</td>\n",
       "      <td>0.054517</td>\n",
       "      <td>0.982564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.041748</td>\n",
       "      <td>0.987684</td>\n",
       "      <td>0.053225</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.042458</td>\n",
       "      <td>0.987684</td>\n",
       "      <td>0.052564</td>\n",
       "      <td>0.983590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.042644</td>\n",
       "      <td>0.987684</td>\n",
       "      <td>0.051787</td>\n",
       "      <td>0.984615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.052803</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.042458</td>\n",
       "      <td>0.986315</td>\n",
       "      <td>0.052303</td>\n",
       "      <td>0.984615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.042953</td>\n",
       "      <td>0.986315</td>\n",
       "      <td>0.052416</td>\n",
       "      <td>0.983590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.042295</td>\n",
       "      <td>0.985973</td>\n",
       "      <td>0.056117</td>\n",
       "      <td>0.982564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.044935</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.053283</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.044365</td>\n",
       "      <td>0.986315</td>\n",
       "      <td>0.057169</td>\n",
       "      <td>0.983590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.044371</td>\n",
       "      <td>0.985631</td>\n",
       "      <td>0.058340</td>\n",
       "      <td>0.980513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.042734</td>\n",
       "      <td>0.989052</td>\n",
       "      <td>0.056028</td>\n",
       "      <td>0.983590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.985289</td>\n",
       "      <td>0.052454</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.046138</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.053890</td>\n",
       "      <td>0.983590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.051815</td>\n",
       "      <td>0.982894</td>\n",
       "      <td>0.068146</td>\n",
       "      <td>0.977436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.052079</td>\n",
       "      <td>0.982210</td>\n",
       "      <td>0.070212</td>\n",
       "      <td>0.977436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.058576</td>\n",
       "      <td>0.980842</td>\n",
       "      <td>0.052184</td>\n",
       "      <td>0.983590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.048667</td>\n",
       "      <td>0.983236</td>\n",
       "      <td>0.071330</td>\n",
       "      <td>0.981538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.049219</td>\n",
       "      <td>0.984605</td>\n",
       "      <td>0.056896</td>\n",
       "      <td>0.984615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.051070</td>\n",
       "      <td>0.983921</td>\n",
       "      <td>0.060272</td>\n",
       "      <td>0.979487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.044390</td>\n",
       "      <td>0.985289</td>\n",
       "      <td>0.053141</td>\n",
       "      <td>0.984615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.041931</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.053230</td>\n",
       "      <td>0.982564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.042025</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.054827</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.044648</td>\n",
       "      <td>0.985631</td>\n",
       "      <td>0.052882</td>\n",
       "      <td>0.985641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "155  0.054798  0.983579  0.056008      0.983590\n",
       "156  0.048680  0.984605  0.061054      0.980513\n",
       "157  0.043788  0.986315  0.057210      0.982564\n",
       "158  0.045296  0.987000  0.052046      0.983590\n",
       "159  0.043013  0.985973  0.054348      0.983590\n",
       "160  0.043163  0.987342  0.054275      0.982564\n",
       "161  0.044497  0.986658  0.054517      0.982564\n",
       "162  0.041748  0.987684  0.053225      0.985641\n",
       "163  0.042458  0.987684  0.052564      0.983590\n",
       "164  0.042644  0.987684  0.051787      0.984615\n",
       "165  0.043500  0.987000  0.052803      0.985641\n",
       "166  0.042458  0.986315  0.052303      0.984615\n",
       "167  0.042953  0.986315  0.052416      0.983590\n",
       "168  0.042295  0.985973  0.056117      0.982564\n",
       "169  0.044935  0.987000  0.053283      0.985641\n",
       "170  0.044365  0.986315  0.057169      0.983590\n",
       "171  0.044371  0.985631  0.058340      0.980513\n",
       "172  0.042734  0.989052  0.056028      0.983590\n",
       "173  0.045400  0.985289  0.052454      0.985641\n",
       "174  0.046138  0.987000  0.053890      0.983590\n",
       "175  0.051815  0.982894  0.068146      0.977436\n",
       "176  0.052079  0.982210  0.070212      0.977436\n",
       "177  0.058576  0.980842  0.052184      0.983590\n",
       "178  0.048667  0.983236  0.071330      0.981538\n",
       "179  0.049219  0.984605  0.056896      0.984615\n",
       "180  0.051070  0.983921  0.060272      0.979487\n",
       "181  0.044390  0.985289  0.053141      0.984615\n",
       "182  0.041931  0.987000  0.053230      0.982564\n",
       "183  0.042025  0.987000  0.054827      0.985641\n",
       "184  0.044648  0.985631  0.052882      0.985641"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8263f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b1448f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08709528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464fbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae9a79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e3eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d5dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadfd64c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4e156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beeb839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12b7514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
